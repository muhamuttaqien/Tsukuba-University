{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer: A Novel [Google](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) Language Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_masks, show_plot_evaluation, translate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Iterator import batch_size_fn, Iterator\n",
    "from Tokenizer import Tokenizer\n",
    "from Embedder import Embedder\n",
    "from PositionalEncoder import PositionalEncoder\n",
    "from Sublayers import Norm, MultiHeadedSelfAttention, FeedForward\n",
    "from Layers import EncoderLayer, DecoderLayer\n",
    "from Scheduler import CosineWithRestarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1 # 100\n",
    "N_LAYERS = 6\n",
    "N_HEADS = 8\n",
    "D_MODEL = EMBEDDING_DIM = 512 # this can be the length of the longest sentence in our training dataset\n",
    "MAX_LENGTH = 80\n",
    "\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 1500\n",
    "LR = 0.0001\n",
    "\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.98\n",
    "EPS = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda: device = torch.device('cuda')\n",
    "else: device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_LANG = 'en_core_web_sm'\n",
    "TARGET_LANG = \"fr_core_news_sm\"\n",
    "\n",
    "SOURCE_DATA = open('./datasets/english.txt').read().strip().split('\\n')\n",
    "TARGET_DATA = open('./datasets/french.txt').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_source = Tokenizer(SOURCE_LANG)\n",
    "token_target = Tokenizer(TARGET_LANG)\n",
    "\n",
    "SOURCE_FIELD = data.Field(lower=True, tokenize=token_source.tokenize)\n",
    "TARGET_FIELD = data.Field(lower=True, tokenize=token_target.tokenize, init_token='<SOS>', eos_token='<EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Help!</td>\n",
       "      <td>À l'aide !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE      TARGET\n",
       "0    Go.        Va !\n",
       "1   Run!     Cours !\n",
       "2   Run!    Courez !\n",
       "3  Fire!    Au feu !\n",
       "4  Help!  À l'aide !"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {'SOURCE': [line for line in SOURCE_DATA], 'TARGET': [line for line in TARGET_DATA]}\n",
    "df_datasets = pd.DataFrame(raw_data, columns=['SOURCE', 'TARGET'])\n",
    "df_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_datasets['SOURCE'].str.count(' ') < MAX_LENGTH) & (df_datasets['TARGET'].str.count(' ') < MAX_LENGTH)\n",
    "df_datasets = df_datasets.loc[mask]\n",
    "\n",
    "df_datasets.to_csv('./datasets/translate_transformer_temp.csv', index=False)\n",
    "data_fields = [('SOURCE', SOURCE_FIELD), ('TARGET', TARGET_FIELD)]\n",
    "train = data.TabularDataset('./datasets/translate_transformer_temp.csv', format='csv', fields=data_fields)\n",
    "train_iter = Iterator(train, batch_size=BATCH_SIZE, device=device, repeat=False, \n",
    "                      sort_key=lambda x: (len(x.SOURCE), len(x.TARGET)),\n",
    "                      batch_size_fn=batch_size_fn, train=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FIELD.build_vocab(train)\n",
    "TARGET_FIELD.build_vocab(train)\n",
    "\n",
    "pickle.dump(SOURCE_FIELD, open('datasets/SOURCE.pkl', 'wb'))\n",
    "pickle.dump(TARGET_FIELD, open('datasets/TARGET.pkl', 'wb'))\n",
    "\n",
    "SOURCE_PAD = SOURCE_FIELD.vocab.stoi['<PAD>']\n",
    "TARGET_PAD = TARGET_FIELD.vocab.stoi['<PAD>']\n",
    "\n",
    "for i, b in enumerate(train_iter): \n",
    "    TRAIN_LENGTH = i\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab_size = len(SOURCE_FIELD.vocab)\n",
    "target_vocab_size = len(TARGET_FIELD.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build [Transformer](https://arxiv.org/pdf/1706.03762.pdf) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, heads, N, d_model, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "            \n",
    "        # function for duplicating encoder layers\n",
    "        def get_clones(module, N):\n",
    "            return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "        self.N = N\n",
    "        self.embedding_layer = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.encoder_layer = get_clones(EncoderLayer(heads, d_model, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    \n",
    "    def forward(self, source_seq, mask):\n",
    "        \n",
    "        source_seq = source_seq.to(device)\n",
    "        \n",
    "        x = self.embedding_layer(source_seq)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.encoder_layer[i](x, mask, device)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, heads, N, d_model, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # function for duplicating decoder layers\n",
    "        def get_clones(module, N):\n",
    "            return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "        \n",
    "        self.N = N\n",
    "        self.embedding_layer = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.decoder_layer = get_clones(DecoderLayer(heads, d_model, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        \n",
    "    def forward(self, target_seq, encoder_outputs, source_mask, target_mask):\n",
    "        \n",
    "        target_seq = target_seq.to(device)\n",
    "        \n",
    "        x = self.embedding_layer(target_seq)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.decoder_layer[i](x, encoder_outputs, source_mask, target_mask, device)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, source_vocab, target_vocab, heads, N, d_model, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(source_vocab, heads, N, d_model, dropout)\n",
    "        self.decoder = Decoder(target_vocab, heads, N, d_model, dropout)\n",
    "        self.output_layer = nn.Linear(d_model, target_vocab)\n",
    "        \n",
    "    # this transformer doesn't perform softmax on the output\n",
    "    # the process will be handled automatically by our loss function\n",
    "    def forward(self, source_seq, target_seq, source_mask, target_mask):\n",
    "        \n",
    "        encoder_outputs = self.encoder(source_seq, source_mask)\n",
    "        decoder_output = self.decoder(target_seq, encoder_outputs, source_mask, target_mask)\n",
    "        output = self.output_layer(decoder_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(source_vocab_size, target_vocab_size, N_HEADS, N_LAYERS, D_MODEL, DROPOUT)\n",
    "transformer.to(device)\n",
    "for p in transformer.parameters(): \n",
    "    if p.dim() > 1: nn.init.xavier_uniform_(p)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(predictions, labels, ignore_index):\n",
    "    \n",
    "    loss = F.cross_entropy(predictions.view(-1, predictions.size(-1)), labels, ignore_index=ignore_index)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=LR, betas=(BETA1, BETA2), eps=EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineWithRestarts(optimizer=optimizer, T_max=TRAIN_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network...\n",
      "Time: 222m, Epoch: 1 [####################] 100%, Loss = 5.104\n",
      "Epoch 1 complete, Loss: 5.104\n"
     ]
    }
   ],
   "source": [
    "temp = tick = time.time()\n",
    "\n",
    "losses_history = []\n",
    "print_every = 100\n",
    "\n",
    "print('Training the network...')\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        \n",
    "        source = batch.SOURCE.transpose(0,1)\n",
    "        target = batch.TARGET.transpose(0,1)\n",
    "        target_input = target[:, :-1] # the network produces the outputs one at a time\n",
    "        source_mask, target_mask = create_masks(source, target_input, SOURCE_PAD, TARGET_PAD, device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = transformer(source, target_input, source_mask, target_mask)\n",
    "        labels = target[:, 1:].contiguous().view(-1)\n",
    "        loss = ce_loss(predictions, labels, ignore_index=TARGET_PAD)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            p = int(100 * i / TRAIN_LENGTH)\n",
    "            avg_loss = total_loss/ print_every\n",
    "            print('Time: %dm, Epoch: %d [%s%s] %d%%, Loss = %.3f' %\\\n",
    "                  ((time.time() - tick)//60, epoch, ''.join('#'*(p//5)), ''.join(' '*(20-(p//5))), p, avg_loss), end='\\r')\n",
    "            \n",
    "            total_loss = 0\n",
    "    \n",
    "    # plot average loss for evaluation\n",
    "    losses_history.append(avg_loss)\n",
    "    print('Time: %dm, Epoch: %d [%s%s] %d%%, Loss = %.3f\\nEpoch %d complete, Loss: %.03f' %\\\n",
    "        ((time.time() - tick)//60, epoch, ''.join('#'*(100//5)), ''.join(' '*(20-(100//5))), 100, avg_loss, epoch, avg_loss))\n",
    "          \n",
    "    # save models per each epoch\n",
    "    if not os.path.exists('./weights/'): os.makedirs('./weights/')\n",
    "    torch.save(transformer.state_dict(), 'weights/transformer.hdf5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plot_evaluation(losses_history, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Tu tu vous tu vous\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'what are you thinking?'\n",
    "\n",
    "phrase = translate_text(text, transformer, SOURCE_FIELD, TARGET_FIELD, MAX_LENGTH, device)\n",
    "print('> ' + phrase + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> J'j'ai..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'i love artificial intelligence'\n",
    "\n",
    "phrase = translate_text(text, transformer, SOURCE_FIELD, TARGET_FIELD, MAX_LENGTH, device)\n",
    "print('> ' + phrase + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Vous vous vous vous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'you are wonderful!'\n",
    "\n",
    "phrase = translate_text(text, transformer, SOURCE_FIELD, TARGET_FIELD, MAX_LENGTH, device)\n",
    "print('> ' + phrase + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'for the brighter future!'\n",
    "\n",
    "phrase = translate_text(text, transformer, SOURCE_FIELD, TARGET_FIELD, MAX_LENGTH, device)\n",
    "print('> ' + phrase + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Il il il il il,,,,,,,,,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'If we wanted to travel around the world, could we buy the tickets tomorrow?'\n",
    "\n",
    "phrase = translate_text(text, transformer, SOURCE_FIELD, TARGET_FIELD, MAX_LENGTH, device)\n",
    "print('> ' + phrase + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
